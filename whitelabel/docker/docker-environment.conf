wasp {

  # framework-related configuration

  #actor-system-name =
  #actor-downing-timeout-millis =  # do not change unless you know what you're doing
  #environment.prefix =
  systempipegraphs.start = false # whether to automatically start system pipegraphs
  systemproducers.start = false # whether to automatically start system producers
  #index-rollover =
  #general-timeout-millis =
  #services-timeout-millis =

  rest {
    server {
      hostname = "master"
      #port =
    }
  }

  #datastore {
  #  indexed =
  #  keyvalue =
  #}

  akka {
    #loglevel =
    #loggers =
    #logging-filter =
    #logger-startup-timeout =
    #log-dead-letters =
    #log-dead-letters-during-shutdown =

    #remote {
    #  log-remote-lifecycle-events =
    #  enabled-transports =
    #  netty.tcp {
    #    port =
    #    hostname =
    #  }
    #}

    #actor {
    #  provider =
    #}

    cluster {
      #log-info =
      seed-nodes = ["akka.tcp://WASP@master:2892"]
      #gossip-interval =
      #publish-stats-interval =
      #metrics.gossip-interval =
      #metrics.collect-interval =
    }
  }


  # external-services-related configuration

  mongo {
    address = "mongodb://mongo:27017"
    #db-name =
    #timeout =
  }

  kafka {
    connections = [{
      protocol = ""
      host = "kafka"
      port = 9092
      timeout = ${wasp.services-timeout-millis}
    }]
    zookeeperConnections = [{
      protocol = ""
      host = "zookeeper"
      port = 2181
      timeout = ${wasp.services-timeout-millis}
    }]
    #zkChRoot =
    #ingest-rate =
    #broker-id =
    #partitioner-fqcn =
    #default-encoder =
    #encoder-fqcn =
    #decoder-fqcn =
    #batch-send-size =
  }

  spark-streaming {
    #app-name =
    #master = {
    #  protocol =
    #  host =
    #  port =
    #}
    #driver-cores =
    #driver-memory =
    driver-hostname = "consumers-spark-streaming"
    #driver-bind-address =
    #driver-port =
    #executor-cores =
    #executor-memory =
    #executor-instances =
    #retained-stages-jobs =
    #retained-tasks =
    #retained-executions =
    #retained-batches =
    #yarn-jar =
    #block-manager-port =
    #broadcast-port =
    #fileserver-port =
    #streaming-batch-interval-ms =
    #checkpoint-dir =
    #additional-jars-path =
  }

  spark-batch {
    #app-name =
    #master = {
    #  protocol =
    #  host =
    #  port =
    #}
    #driver-cores =
    #driver-memory =
    driver-hostname = "consumers-spark-batch"
    #driver-bind-address =
    #driver-port =
    #executor-cores =
    #executor-memory =
    #executor-instances =
    #retained-stages-jobs =
    #retained-tasks =
    #retained-executions =
    #retained-batches =
    #yarn-jar =
    #block-manager-port =
    #broadcast-port =
    #fileserver-port =
    #additional-jars-path =
  }

  elastic {
    connections = [
      {
        protocol = ""
        host = "elasticsearch"
        port = 9300
        timeout = ${wasp.services-timeout-millis}
        metadata = [
          {"connectiontype": "binary"}
        ]
      },
      {
        protocol = ""
        host = "elasticsearch"
        port = 9200
        timeout = ${wasp.services-timeout-millis}
        metadata = [
          {"connectiontype": "rest"}
        ]
      }
    ]
    #cluster-name =
  }

  solrcloud {
    zookeeperConnections = [
      {
        protocol = ""
        host = "zookeeper"
        port = 2181
        metadata = [
          {"zookeeperRootNode": ""}
        ]
      }
    ]
    #name =
    #cluster_name =
    apiEndPoint = {
      #protocol =
      host = "solr"
      #port =
      #metadata = [
      #
      #]
    }
    #zkChRoot =
  }

  #hbase {
  #  core-site-xml-path =
  #  hbase-site-xml-path =
  #}

  jdbc {
   connections = [
  # {
  #   name =
  #   dbType =
  #   host =
  #   port =
  #   user =
  #   password =
  #   driverName =
  #   #partitioningInfo = {
  #   #  partitionColumn =
  #   #  lowerBound =
  #   #  upperBound =
  #   #}
  #   #numPartitions =
  #   #fetchSize =
  # }
   ]
  }
}