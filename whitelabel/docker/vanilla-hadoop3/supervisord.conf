[supervisord]
nodaemon=true
environment=HADOOP_CONF_DIR="/etc/hadoop/conf:/etc/hbase/conf",HOSTNAME=%(ENV_HOSTNAME)s

[program:master]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/master/
command=/code/master/bin/wasp-whitelabel-master
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
  -J-Xmx1g -J-Xms512m
  -Dlog4j.configuration=file:///log4j-master.properties
  -Dlog4j.debug=true
  -Dconfig.file=/wasp.conf
  -Dwasp.process="---master"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2892
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"
  -Dwasp.akka.cluster.roles.0="master"

[program:producers]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/producer/
command=/code/producer/bin/wasp-whitelabel-producers
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5006
  -J-Xmx1g -J-Xms512m
  -Dlog4j.configuration=file:///log4j-producer.properties
  -Dlog4j.debug=true
  -Dconfig.file=/wasp.conf
  -Dwasp.process="producers"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2893
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"

[program:consumers-streaming]
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
environment=WASP_HOME=/code/consumers-spark/
command=/code/consumers-spark/bin/spark-consumers-streaming-node-launcher
  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5007
  -J-Xmx1g -J-Xms512m
  -Dlog4j.debug=true
  -Dlog4j.configuration=file:///log4j-consumer.properties
  -Dconfig.file=/wasp.conf
  -Dwasp.process="streaming"
  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
  -Dwasp.akka.remote.netty.tcp.port=2894
  -Dwasp.akka.cluster.roles.0="consumers-spark-streaming-collaborator"
  -Dwasp.akka.cluster.roles.1="consumers-spark-streaming"
  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"

[program:parallel-write-entity]
environment=MINIO_ROOT_USER=%(ENV_MINIO_ROOT_USER)s,MINIO_ROOT_PASSWORD=%(ENV_MINIO_ROOT_PASSWORD)s
stdout_logfile=/dev/fd/1
stdout_logfile_maxbytes=0
stderr_logfile=/dev/fd/2
stderr_logfile_maxbytes=0
startsecs=30
exitcodes=0,2
stopsignal=TERM
stopwaitsecs=60
autorestart=unexpected
startretries=999999999
command=python3 /flask-parallel-write-entity.py -t Cold -f Parquet



#[program:consumers-batch]
#stdout_logfile=/dev/fd/1
#stdout_logfile_maxbytes=0
#stderr_logfile=/dev/fd/2
#stderr_logfile_maxbytes=0
#startsecs=30
#exitcodes=0,2
#stopsignal=TERM
#stopwaitsecs=60
#autorestart=unexpected
#startretries=999999999
#environment=WASP_HOME=/code/consumers-spark/
#command=/code/consumers-spark/bin/spark-consumers-batch-node-launcher
#  -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008
#  -J-Xmx1g -J-Xms512m
#  -Dlog4j.configurationFile=file:///log4j2.properties
#  -Dconfig.file=/wasp.conf
#  -Dwasp.process="----batch"
#  -Dwasp.akka.remote.netty.tcp.hostname=%(ENV_HOSTNAME)s
#  -Dwasp.akka.remote.netty.tcp.port=2895
#  -Dwasp.akka.cluster.roles.0="consumers-spark-batch"
#  -Dwasp.akka.cluster.seed-nodes.0="akka.tcp://WASP@%(ENV_HOSTNAME)s:2892"





