wasp {

  # framework-related configuration

  actor-system-name = "WASP"
  actor-downing-timeout-millis = 10000 # do not change unless you know what you're doing
  environment.prefix = ""
  systempipegraphs.start = true # whether to automatically start system pipegraphs
  systemproducers.start = true # whether to automatically start system producers
  index-rollover = false
  general-timeout-millis = 60000
  services-timeout-millis = 15000

  rest {
    server {
      hostname = "localhost"
      port = 2891
    }
  }

  datastore {
    indexed = "solr"
    keyvalue = "hbase"
  }

  akka {
    loglevel = "DEBUG"
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
    logger-startup-timeout = 60s
    log-dead-letters = off
    log-dead-letters-during-shutdown = off

    remote {
      log-remote-lifecycle-events = off
      enabled-transports = ["akka.remote.netty.tcp"]
      netty.tcp {
        port = 2892
        hostname = "localhost"
      }
    }

    actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }

    cluster {
      log-info = on
      seed-nodes = ["akka.tcp://WASP@localhost:2892"]
      gossip-interval = 5s
      publish-stats-interval = 10s
      metrics.gossip-interval = 10s
      metrics.collect-interval = 10s
    }
  }


  # external-services-related configuration

  mongo {
    address = "mongodb://localhost:27017"
    db-name = "wasp"
    timeout = ${wasp.services-timeout-millis}
  }

  kafka {
    connections = [{
      protocol = ""
      host = "localhost"
      port = 9092
      timeout = ${wasp.services-timeout-millis}
      metadata = []
    }]
    zookeeperConnections = [{
      protocol = ""
      host = "localhost"
      port = 2181
      timeout = ${wasp.services-timeout-millis}
      metadata = []
    }]
    zkChRoot = "/kafka"
    ingest-rate = "1s"
    broker-id = 0
    partitioner-fqcn = "kafka.producer.DefaultPartitioner"
    default-encoder = "kafka.serializer.DefaultEncoder"
    encoder-fqcn = "kafka.serializer.StringEncoder"
    decoder-fqcn = "kafka.serializer.StringDecoder"
    batch-send-size = 0
  }

  spark-streaming {
    app-name = "WASP-streaming"
    master {
      protocol = ""
      host = "local[*]"
      port = 0
    }
    driver-conf {
      submit-deploy-mode = "client"
      driver-cores = 1
      driver-memory = "1G"
      driver-hostname = "localhost"
      driver-bind-address = "0.0.0.0"
      driver-port = 0
    }
    executor-cores = 2
    executor-memory = "1G"
    executor-instances = 1
    additional-jars-path = "/root/wasp/lib"
    yarn-jar = "./spark-lib/spark-assembly.jar"
    block-manager-port = 0
    broadcast-port = 0
    fileserver-port = 0
    retained-stages-jobs = 100
    retained-tasks = 5000
    retained-jobs = 100
    retained-executions = 100
    retained-batches = 100

    streaming-batch-interval-ms = 1000
    checkpoint-dir = "./tmp"
  }

  spark-batch {
    app-name = "WASP-batch"
    master {
      protocol = ""
      host = "local[*]"
      port = 0
    }
    driver-conf {
      submit-deploy-mode = "client"
      driver-cores = 1
      driver-memory = "1G"
      driver-hostname = "localhost"
      driver-bind-address = "0.0.0.0"
      driver-port = 0
    }
    executor-cores = 2
    executor-memory = "1G"
    executor-instances = 1
    additional-jars-path = "/root/wasp/lib"
    yarn-jar = "./spark-lib/spark-assembly.jar"
    block-manager-port = 0
    broadcast-port = 0
    fileserver-port = 0
    retained-stages-jobs = 100
    retained-tasks = 5000
    retained-jobs = 100
    retained-executions = 100
    retained-batches = 100
  }

  elastic {
    connections = [
      {
        protocol = ""
        host = "localhost"
        port = 9300
        timeout = ${wasp.services-timeout-millis}
        metadata = [
          {"connectiontype": "binary"}
        ]
      },
      {
        protocol = ""
        host = "localhost"
        port = 9200
        timeout = ${wasp.services-timeout-millis}
        metadata = [
          {"connectiontype": "rest"}
        ]
      }
    ]
  }

  solrcloud {
    zookeeperConnections = [{
      protocol = ""
      host = "localhost"
      port = 2181
      timeout = ${wasp.services-timeout-millis}
      metadata = []
    }]
    zkChRoot = "/solr"
  }

  hbase {
    core-site-xml-path = "/etc/hbase/conf/core-site.xml"
    hbase-site-xml-path = "/etc/hbase/conf/hbase-site.xml"
  }

  jdbc {
    connections {
      #CONNECTION_NAME {
      #  url = "jdbc:oracle:thin://HOST:PORT/DB"
      #  user = "USER"
      #  password = "PSW"
      #  driverName = "DRIVER_FULLY_QUALIFIED_NAME"
      #}
      # #Examples
      #mysql {
      #  url = "jdbc:mysql://mysql:3306/test_db"
      #  user = "root"
      #  password = "psw"
      #  driverName = "com.mysql.jdbc.Driver"
      #}
      #oracle {
      #  url = "jdbc:oracle:thin://oracl:1521/ORCLCDB.localdomain"
      #  user = "user"
      #  password = "psw"
      #  driverName = "oracle.jdbc.driver.OracleDriver"
      #}
    }
  }
}